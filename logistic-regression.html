---
title: "Logistic Regression Assignment"
author: "Chris McLoy"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r includes, echo=F, warning=F, message=F}
library(tidyverse)
library(scales)
library(readr)
library(forcats)
library(broom)
```


## Logistic Regression

Logistic regression allows us to apply the power of regression to 
cases where our outcome variable is binary (0/1). The fitting process and 
coefficient interpretation are quite a bit different from linear 
regression. The technique is powerful and pretty ubiquitous in business,
where there are many problems with binary outcomes (e.g., purchasing, 
re-purchasing, customer attrition, etc.)

## Instructions

Follow along in this document. There are places where I've added comments
encouraging you to do analyses, make plots, etc. In the modeling
section I've asked you to build a logistic regression model and in the
interpretation section I've asked you to interpret it. Do so, then
knit your model and commit both your knitted HTML and your RMD. 

## Data

The data for this project comes from a local company, TOMIS, who manages
bookings, websites, and marketing for a variety of tour operators. They've 
graciously allowed us to use a sample of data on customer booking habits. The 
data is pretty large (~52 MB) and can be downloaded from Moodle. Once you've 
downloaded it, extract it from its zip file into this folder. 

```{r data-input, echo = F, message=F}
input.data.file <- "trip_scoring_data.txt"

d <- read_tsv(input.data.file)

```

The data set has the following columns: 

1. `id`: a unique identifier for the customer.
1. `total_spent`: the amount of money the customer has spent with the tour operator. 
1. `days_since_last`: the number of days since the last time the customer booked with this
operator. 
1. `bookings_in_last_13_months`: the number of bookings in the preceding 13 months. 
1. `bookings_in_13_to_26_months`: the number of bookings 13 to 26 months ago. 
1. `bookings_more_than_26_months`: the number of bookings more than 26 months ago. 
1. `mean_dist_to_client_location`: the mean distance from the customer to the tour
operator. This is missing for about 35\% of rows. 
1. `mean_leading_days`: the mean number of days that the customer books their experiences.
1. `mean_rebook_days`: if the customer rebooks, the mean number of days between those rebookings.
1. `booking_dt`: the calendar date and time of the booking.
1. `experience_dt`: the calendar date and time of the experience, which is what the tours or 
trips are called. 
1. `client`: There are 14 clients in the data set. These are the tour operators.
1. `client_location`: Some clients have multiple locations. This field allows us to differentiate
between them. 
1. `guests`: The number of people on the experience.
1. `domain`: the web domain of the customer's email. 
1. `rebooked`: our response variable. Zero or one depending on whether or not the customer
rebooks. There are 12.4\% of rows that have rebookings. 


## Data Exploration

<!-- Feel free to use this space to do any data exploration you'd like. I'll get you started --> 

Let's take a look at rebooking rates by client:

```{r "client-rebooking-rate", message=F, echo= F, eval = T}
d %>% 
  group_by(client) %>% 
  summarize(mean_rebook = mean(rebooked)) %>% 
  mutate(client = fct_reorder(client,mean_rebook)) %>% 
  ggplot(aes(x=mean_rebook,y=client)) + 
  geom_point() + 
  theme_minimal() + 
  labs(x="Rebooking Rate",
       y="Tour Operator") +
  scale_x_continuous(label=percent)


```

As we can see, there's quite a bit of variability in rebooking rates across clients. Therefore,
client is likely to be a useful explanatory variable in our model. 

## Model

<!-- Use this section to build a model of rebooking. 
     I have some code to get you started. On my machine I can 
     fit the full model, but you may not be able to, so I included some code
     to allow you to subset the data. --> 


```{r model, echo=F, eval=T}

d <- d %>% 
  mutate(client_fct = fct_reorder(client,rebooked,mean))

glm.1 <- glm(rebooked ~ client_fct + 
                    total_spent + bookings_in_13_to_26_months + 
                  mean_leading_days,
                  data=d %>% slice_sample(prop=0.5),
                  family="binomial",
                  subset=total_spent < 20000)


rb.fit <- tidy(glm.1) %>% 
  mutate(exp_estimate = exp(estimate),
         lb = exp(estimate - 2*std.error),
         ub = exp(estimate + 2*std.error)) %>% 
  mutate(pretty_term = if_else(grepl("client",term),
                               gsub("client_fct","",term),
                               term))


summary(glm.1)

```

<!-- Discuss the model fitting process and the final model you arrived at. --> 

The process I took was trial and error. At first I took the variables client_fct, total_spent, bookings > 26 months, and mean_leading days. Each one besides bookings >26 months had extremely low p values. Although the bookings > 26 months was still within the %5 acceptance range, I tried another model. 

From here I went with the next booking timeframe and that was 13 to 26 months. With this all variables were significantly small. The final model I arrived had included the variables of client_fct, total_spent, bookings between 13 and 26 months, and mean_leading days.

With this model, it shows the Bulldog Tours as being the response variable, while total_spent, bookings between 13 and 26 months, and mean_leading days are the explanatory vairables. In viewing the chart above, we see that for every $1 total_spent, the number of bulldog tours increased by 6.119e-04 while holding all other explanatory variables at 0. Where as for every 1 increase in bookings between 13-26 months, we see an increase in Bulldog Tours by 2.239e-01 and similar with every 1 increase in mean leading days we see an increase in Bulldog Tours of 3.640e-03.


## Interpretation

As discussed above the model created has great significance when comparing the variables (total spent, bookings between 13 and 26 months, and mean leading days). The code below pulls in data and shows the probably of rebookings using the client function and holding all other items equal. With this, we show that the probability for someone to rebook going to Handlebar is less than 9%, while the probability to rebook to ocoee-zipz is 40.37% all have an average mean rebooking time of 19.3 days and an average spent of $222.   

```{r probability database, echo= F, eval= T}

new.d <- tibble(client_fct= unique(d$client_fct),
                total_spent = mean(d$total_spent, na.rm = T),
                mean_leading_days = mean(d$mean_leading_days, na.rm = T),
                bookings_in_13_to_26_months= mean(d$bookings_in_13_to_26_months, na.rm= T))
new.d <- new.d %>%
  mutate(prob = predict(glm.1, newdata = new.d, type = "response"))

new.d

```

```{r clien-plot, echo=F, eval=T}
ggplot(rb.fit %>% 
         filter(grepl("client",term)) %>% 
         mutate(pretty_term = fct_reorder(pretty_term,exp_estimate)),
       aes(x=exp_estimate,y=pretty_term)) + 
  geom_point() + 
  geom_errorbarh(aes(xmin=lb,xmax=ub,y=pretty_term),
                 height=0) + 
  theme_minimal() + 
  labs(x="Odds Multiplier",
       y="Model Term") + 
  geom_vline(xintercept=1,col="gray70")


```

## Accuracy

<!--    
    Do a new fit of your model on a subset of your data, then evaluate it on the 
    portion not used for fitting. Logistic regression models output probabilities, 
    so you could compare the `rebooked` column to your rounded predicted probability. 
    I have some code to help you out with this. --> 


```{r accuracy,warning=F, echo=F, eval = T}
  holdout.d <- d %>% 
    slice_sample(prop=0.1) %>% 
    select(id,rebooked)

  glm.test <- update(glm.1,subset=!(id %in% holdout.d$id))
  
  holdout.d <- holdout.d %>% 
    mutate(predicted_val = predict(glm.1,
                                   newdata=d %>% 
                                     filter(id %in% holdout.d$id)))
  holdout.d <- holdout.d %>% 
    mutate(est_rebooked = as.numeric(predicted_val >= 0.5))
  
  confusion.mat <- table(holdout.d$rebooked,holdout.d$est_rebooked)
  
  rownames(confusion.mat) <- c("Didn't Rebook","Did Rebook")
  colnames(confusion.mat) <- c("Pred No Rebook","Pred Rebook")

  knitr::kable(confusion.mat)
  
```

<!-- Your interpretation here. In my example we don't do a great job period, 
     although we're okay at predicting the didn't rebook group. --> 

The model I predicted provided an 88.9% accuracy rate for the No Rebook attribute. So the over all the classifier is 88.9% correct, but our true postive rate is less than 1%. Thus we are great at saying what money wont be coming in, but what money would come in. :) 